attention_resolutions: 16,8
class_cond: false
diffusion_steps: 1000
learn_sigma: false
noise_schedule: linear
num_channels: 128
num_head_channels: 64
num_heads: 4
num_res_blocks: 3
resblock_updown: false
use_fp16: false
use_scale_shift_norm: true
classifier_scale: 1.0
lr_kernel_n_std: 2
num_samples: 1
show_progress: true
timestep_respacing: 'ddim200'
use_kl: false
predict_xstart: false
rescale_timesteps: false
rescale_learned_sigmas: false
classifier_use_fp16: false
classifier_width: 128
classifier_depth: 2
classifier_attention_resolutions: 32,16,8
classifier_use_scale_shift_norm: true
classifier_resblock_updown: true
classifier_pool: attention
num_heads_upsample: -1
channel_mult: ''
dropout: 0.0
use_checkpoint: false
use_new_attention_order: false
clip_denoised: true
use_ddim: true
image_size: 256
# classifier_path: ./data/pretrained/256x256_classifier.pt
model_path: ../work_dirs/fib25_xy/model090000.pt


name: fib25
in_channels: 3

inpa_inj_sched_prev: true
n_jobs: 25
print_estimated_vars: true
inpa_inj_sched_prev_cumnoise: false
schedule_jump_params:
  t_T: 200
  n_sample: 1
  jump_length: 10
  jump_n_sample: 10
data:
  eval:
    lama_inet256_thin_n100_test:
      mask_loader: true
      gt_path: ./data/2pm/gt
      mask_path: ./data/2pm/mask
      image_size: 128
      class_cond: false
      deterministic: true
      random_crop: false
      random_flip: false
      return_dict: true
      drop_last: false
      batch_size: 2
      return_dataloader: true
      ds_conf:
        name: random_thin_256
      max_len: 4
      paths:
        srs: ./log/fib25/inpainted
        lrs: ./log/fib25/gt_masked
        gts: ./log/fib25/gt
        gt_keep_masks: ./log/fib25/gt_keep_mask
